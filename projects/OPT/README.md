## About OPT
OPT (Open Pre-trained Transformers) is a family of NLP models trained on billions of tokens of text obtained from the internet.

## Pretrained Model Weights
| Model    | Parameters | Pretrained weights  |
|----------|:----------:|:-------------------:|
| OPT-125M |    125M    |        link         |
| OPT-350M |    350M    |        link         |
| OPT-1.3B |    1.3B    |        link         |
| OPT-2.7B |    2.7B    |        link         |
| OPT-6.7B |    6.7B    |        link         |
| OPT-30B  |    30B     |        link         |
| OPT-66B  |    66B     |        link         |
| OPT-175B |    175B    | request access here |


## Model card & data card
We are including a model card [Mitchell et al., 2019] and data card [Gebru et al., 2021] to help with transparency and accountability in model development.
* [Model card](./model_card.md) 
* [Data card](./data_card.md)


## License
The use of OPT model weights is subject to the [Model License](./MODEL_LICENSE.md).

